{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for combining the six unicommerce dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def process_files(file_paths, output_path):\n",
    "    # Initialize an empty list to hold DataFrames\n",
    "    dataframes = []\n",
    "\n",
    "    # Iterate over file paths and load each file\n",
    "    for i, input_path in enumerate(file_paths):\n",
    "        # Validate the file path\n",
    "        if not os.path.exists(input_path):\n",
    "            print(f\"Error: File not found at {input_path}\")\n",
    "            return\n",
    "        \n",
    "        # Load the data based on file type (CSV or Excel)\n",
    "        try:\n",
    "            if input_path.endswith('.csv'):\n",
    "                df = pd.read_csv(input_path, low_memory=False)\n",
    "            else:\n",
    "                df = pd.read_excel(input_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {input_path}: {e}\")\n",
    "            return\n",
    "\n",
    "        # Check if the file is among the first three (export courier) or the last three (export reverse)\n",
    "        if i < 3:  # For the first three files (Export Courier)\n",
    "            df = df[['AWB No', 'Shipping Package Status']]\n",
    "        else:  # For the last three files (Export Reverse)\n",
    "            df = df.rename(columns={'Tracking No': 'AWB No', 'Reverse Pickup Status': 'Shipping Package Status'})\n",
    "            df = df[['AWB No', 'Shipping Package Status']]\n",
    "        \n",
    "        # Add the DataFrame to the list\n",
    "        dataframes.append(df)\n",
    "\n",
    "    # Combine all DataFrames into a single DataFrame\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Save the combined DataFrame to the specified output path\n",
    "    try:\n",
    "        if output_path.endswith('.csv'):\n",
    "            combined_df.to_csv(output_path, index=False)\n",
    "        else:\n",
    "            combined_df.to_excel(output_path, index=False)\n",
    "        print(f\"Combined file saved to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving the file: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Provide paths for six input files\n",
    "    file_paths = [\n",
    "        input(\"Enter the path for export courier file 1 (CSV or XLSX): \"),\n",
    "        input(\"Enter the path for export courier file 2 (CSV or XLSX): \"),\n",
    "        input(\"Enter the path for export courier file 3 (CSV or XLSX): \"),\n",
    "        input(\"Enter the path for export reverse file 4 (CSV or XLSX): \"),\n",
    "        input(\"Enter the path for export reverse file 5 (CSV or XLSX): \"),\n",
    "        input(\"Enter the path for export reverse file 6 (CSV or XLSX): \")\n",
    "    ]\n",
    "    \n",
    "    # Get the output file path\n",
    "    output_path = input(\"Enter the path for the output file (CSV or XLSX): \")\n",
    "    \n",
    "    # Add '.xlsx' as default if no valid extension is provided\n",
    "    if not output_path.endswith(('.csv', '.xlsx')):\n",
    "        output_path += '.xlsx'\n",
    "    \n",
    "    # Process and combine the files\n",
    "    process_files(file_paths, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaned the dataset for comparsion and make it correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the provided Excel files\n",
    "output2_file_path = 'C:/Users/gowth/Downloads/script_returns/output2.xlsx'\n",
    "returnv2_file_path = 'C:/Users/gowth/Downloads/script_returns/ReturnV2-2024-09-05T08_39_23.144Z.xlsx'\n",
    "\n",
    "# Load the first sheet of both files\n",
    "output2_df = pd.read_excel(output2_file_path)\n",
    "returnv2_df = pd.read_excel(returnv2_file_path)\n",
    "\n",
    "# Clean the \"Tracking No\" and \"Fwdtracking Id\" columns\n",
    "# Convert both columns to string and ensure proper formatting\n",
    "output2_df['Tracking No'] = output2_df['Tracking No'].astype(str).apply(lambda x: '{:.0f}'.format(float(x)) if 'E+' in x else x)\n",
    "returnv2_df['Fwdtracking Id'] = returnv2_df['Fwdtracking Id'].astype(str).apply(lambda x: '{:.0f}'.format(float(x)) if 'E+' in x else x)\n",
    "\n",
    "# Save the cleaned data back to new Excel files\n",
    "output2_cleaned_file_path = 'output2_cleaned.xlsx'\n",
    "returnv2_cleaned_file_path = 'ReturnV2_cleaned.xlsx'\n",
    "\n",
    "# Write the cleaned data to Excel\n",
    "output2_df.to_excel(output2_cleaned_file_path, index=False)\n",
    "returnv2_df.to_excel(returnv2_cleaned_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the matching with fwdtracking id , awb no and status for forcesight tool and unicommerce data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_files(awb_path, returnv2_path, output_matched_path, output_unmatched_path, output1_path, output2_path, output3_path):\n",
    "    # Load the datasets\n",
    "    awb_df = pd.read_excel(awb_path)\n",
    "    returnv2_df = pd.read_excel(returnv2_path)\n",
    "\n",
    "    # Clean and prepare the data: remove NaN values and strip whitespaces\n",
    "    returnv2_df.dropna(subset=['Fwdtracking Id'], inplace=True)\n",
    "    awb_df['Tracking No'] = awb_df['Tracking No'].astype(str).str.strip()\n",
    "    returnv2_df['Fwdtracking Id'] = returnv2_df['Fwdtracking Id'].astype(str).str.strip()\n",
    "\n",
    "    # Perform a full outer merge to keep all records, even if they don't match\n",
    "    merged_df = pd.merge(returnv2_df, awb_df, how='outer', left_on='Fwdtracking Id', right_on='Tracking No')\n",
    "\n",
    "    # Separate matched and unmatched rows\n",
    "    matched_df = merged_df[merged_df['Tracking No'].notna() & merged_df['Fwdtracking Id'].notna()]\n",
    "    unmatched_df = merged_df[merged_df['Tracking No'].isna() | merged_df['Fwdtracking Id'].isna()]\n",
    "\n",
    "    # Save the results for matched and unmatched rows\n",
    "    matched_df.to_excel(output_matched_path, index=False)\n",
    "    unmatched_df.to_excel(output_unmatched_path, index=False)\n",
    "\n",
    "    # Filtering the data according to the conditions\n",
    "    output1_df = merged_df[\n",
    "        (merged_df['Shipping Package Status'] == 'RETURNED') &\n",
    "        (merged_df['Order Status'].isin(['C RETURN RECEIVED', 'RTO RECEIVED']))\n",
    "    ][['Channel', 'Order ID', 'Order Item ID', 'Order Date', 'SKU', 'Product ID', 'Fulfillment Channel', 'Return Quantity', 'Return Reason', 'Fwdtracking Id', 'Return Date', 'Order Status', 'Shipping Package Status']]\n",
    "\n",
    "    output2_df = merged_df[\n",
    "        ((merged_df['Order Status'] == 'C RETURN RECEIVED') | (merged_df['Order Status'] == 'RTO RECEIVED')) &\n",
    "        (merged_df['Shipping Package Status'].isin(['COURIER_ALLOCATED', 'CREATED', 'RETURN_ACKNOWLEDGED', 'RETURN_EXPECTED', 'COMPLETE']))\n",
    "    ][['Channel', 'Order ID', 'Order Item ID', 'Order Date', 'SKU', 'Product ID', 'Fulfillment Channel', 'Return Quantity', 'Return Reason', 'Fwdtracking Id', 'Return Date', 'Order Status', 'Shipping Package Status']]\n",
    "\n",
    "    # Check if the filtering condition might lead to an empty dataframe\n",
    "    output3_df = merged_df[\n",
    "        ((merged_df['Order Status'] == 'RTO TRANSIT') | (merged_df['Order Status'] == 'C RETURN APPROVED')) &\n",
    "        (merged_df['Shipping Package Status'].isin(['COURIER_ALLOCATED', 'CREATED', 'RETURN_ACKNOWLEDGED', 'RETURN_EXPECTED', 'COMPLETE', 'RETURNED']))\n",
    "    ][['Channel', 'Order ID', 'Order Item ID', 'Order Date', 'SKU', 'Product ID', 'Fulfillment Channel', 'Return Quantity', 'Return Reason', 'Fwdtracking Id', 'Return Date', 'Order Status', 'Shipping Package Status']]\n",
    "\n",
    "    # Ensure dataframes are not empty before renaming and saving\n",
    "    if not output1_df.empty:\n",
    "        output1_df.rename(columns={'Fwdtracking Id': 'AWB No', 'Order Status': 'Forcesight Tool Status', 'Shipping Package Status': 'Unicommerce Status'}, inplace=True)\n",
    "        output1_df.to_excel(output1_path, index=False)\n",
    "    \n",
    "    if not output2_df.empty:\n",
    "        output2_df.rename(columns={'Fwdtracking Id': 'AWB No', 'Order Status': 'Forcesight Tool Status', 'Shipping Package Status': 'Unicommerce Status'}, inplace=True)\n",
    "        output2_df.to_excel(output2_path, index=False)\n",
    "\n",
    "    if not output3_df.empty:\n",
    "        output3_df.rename(columns={'Fwdtracking Id': 'AWB No', 'Order Status': 'Forcesight Tool Status', 'Shipping Package Status': 'Unicommerce Status'}, inplace=True)\n",
    "        output3_df.to_excel(output3_path, index=False)\n",
    "\n",
    "    # Summary of results\n",
    "    matched_count = matched_df.shape[0]\n",
    "    unmatched_count = unmatched_df.shape[0]\n",
    "\n",
    "    print(f\"Matched rows: {matched_count}\")\n",
    "    print(f\"Unmatched rows: {unmatched_count}\")\n",
    "    print(f\"Output1 rows: {output1_df.shape[0] if not output1_df.empty else 0}\")\n",
    "    print(f\"Output2 rows: {output2_df.shape[0] if not output2_df.empty else 0}\")\n",
    "    print(f\"Output3 rows: {output3_df.shape[0] if not output3_df.empty else 0}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Input paths from the user\n",
    "    awb_path = input(\"Enter the path for the AWB dataset (XLSX): \")\n",
    "    returnv2_path = input(\"Enter the path for the ReturnV2 dataset (XLSX): \")\n",
    "    output_matched_path = input(\"Enter the path for the output matched file (XLSX): \")\n",
    "    output_unmatched_path = input(\"Enter the path for the output unmatched file (XLSX): \")\n",
    "    output1_path = input(\"Enter the path for the first filtered output (XLSX): \")\n",
    "    output2_path = input(\"Enter the path for the second filtered output (XLSX): \")\n",
    "    output3_path = input(\"Enter the path for the third filtered output (XLSX): \")\n",
    "\n",
    "    # Process the files\n",
    "    process_files(awb_path, returnv2_path, output_matched_path, output_unmatched_path, output1_path, output2_path, output3_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
